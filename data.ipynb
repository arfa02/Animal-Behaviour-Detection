{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52795fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from opencv-python) (2.2.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9d9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "from shutil import copyfile\n",
    "from dataclasses import dataclass\n",
    "import yaml\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8425d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_unzip(url,save_path):\n",
    "    print(\"Downloading and extracting assets...\",end=\"\")\n",
    "    file = requests.get(url)\n",
    "    open(save_path,\"wb\").write(file.content)\n",
    "\n",
    "    try:\n",
    "        #Extract files\n",
    "        if save_path.endswith(\".tar\"):\n",
    "            with tarfile.open(save_path,\"r\") as tar:\n",
    "                tar.extractall(os.path.split(save_path)[0])\n",
    "\n",
    "        print(\"Done\")\n",
    "    except:\n",
    "        print(\"Invalid file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab15890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting assets...Done\n"
     ]
    }
   ],
   "source": [
    "IMAGES_URL = r\"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
    "IMAGES_DIR = \"Images\"\n",
    "IMAGES_TAR_PATH = os.path.join(os.getcwd(), f\"{IMAGES_DIR}.tar\")\n",
    "\n",
    "ANNS_METADATA_URL = r\"https://github.com/benjiebob/StanfordExtra/raw/master/keypoint_definitions.csv\"\n",
    "ANNS_METADATA = \"keypoint_definitions.csv\"\n",
    "\n",
    "# Download if dataset does not exists.\n",
    "if not os.path.exists(IMAGES_DIR):\n",
    "    download_unzip(IMAGES_URL, IMAGES_TAR_PATH)\n",
    "    os.remove(IMAGES_TAR_PATH)\n",
    "\n",
    "if not os.path.isfile(ANNS_METADATA):\n",
    "    download_unzip(ANNS_METADATA_URL, ANNS_METADATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e9aba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_PATH = \"StanfordExtra_V12\"\n",
    "JSON_PATH = os.path.join(ANN_PATH, \"StanfordExtra_v12.json\")\n",
    "\n",
    "with open(JSON_PATH) as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4fd2964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 6773\n",
      "Validation Samples: 1703\n"
     ]
    }
   ],
   "source": [
    "train_ids = np.load(os.path.join(ANN_PATH,\n",
    "                                 \"train_stanford_StanfordExtra_v12.npy\"))\n",
    "val_ids = np.load(os.path.join(ANN_PATH,\n",
    "                               \"test_stanford_StanfordExtra_v12.npy\"))\n",
    "\n",
    "print(f\"Train Samples: {len(train_ids)}\")\n",
    "print(f\"Validation Samples: {len(val_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a784d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"animal-pose-data\"\n",
    "\n",
    "TRAIN_DIR         = f\"train\"\n",
    "TRAIN_FOLDER_IMG    = f\"images\"\n",
    "TRAIN_FOLDER_LABELS = f\"labels\"\n",
    "\n",
    "TRAIN_IMG_PATH   = os.path.join(DATA_DIR, TRAIN_DIR, TRAIN_FOLDER_IMG)\n",
    "TRAIN_LABEL_PATH = os.path.join(DATA_DIR, TRAIN_DIR, TRAIN_FOLDER_LABELS)\n",
    "\n",
    "VALID_DIR           = f\"valid\"\n",
    "VALID_FOLDER_IMG    = f\"images\"\n",
    "VALID_FOLDER_LABELS = f\"labels\"\n",
    "\n",
    "VALID_IMG_PATH   = os.path.join(DATA_DIR, VALID_DIR, VALID_FOLDER_IMG)\n",
    "VALID_LABEL_PATH = os.path.join(DATA_DIR, VALID_DIR, VALID_FOLDER_LABELS)\n",
    "\n",
    "os.makedirs(TRAIN_IMG_PATH, exist_ok=True)\n",
    "os.makedirs(TRAIN_LABEL_PATH, exist_ok=True)\n",
    "os.makedirs(VALID_IMG_PATH, exist_ok=True)\n",
    "os.makedirs(VALID_LABEL_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "389e1b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "910\n"
     ]
    }
   ],
   "source": [
    "print(type(train_ids))\n",
    "print(train_ids)\n",
    "train_json_data = []\n",
    "for train_id in [train_ids]:\n",
    "    train_json_data.append(json_data[train_id])\n",
    "\n",
    "val_json_data = []\n",
    "for val_id in val_ids:\n",
    "    val_json_data.append(json_data[val_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "281b06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_json_data:\n",
    "    img_file = data[\"img_path\"]\n",
    "    filename = img_file.split(\"/\")[-1]\n",
    "    copyfile(os.path.join(IMAGES_DIR,img_file),\n",
    "             os.path.join(VALID_IMG_PATH,filename))\n",
    "    \n",
    "for data in val_json_data:\n",
    "    img_file = data[\"img_path\"]\n",
    "    filename = img_file.split(\"/\")[-1]\n",
    "    copyfile(os.path.join(IMAGES_DIR,img_file),\n",
    "             os.path.join(VALID_IMG_PATH,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f02355a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91d4f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_boxes_kpts(img_size,boxes,lm_kpts):\n",
    "    IMG_W,IMG_H  = img_size\n",
    "    #modifying the kpts with visibilities as  1s to 2s\n",
    "    vis_ones = np.where(lm_kpts[:, -1] == 1.)\n",
    "    lm_kpts[vis_ones, -1] = 2.\n",
    "    #normalizing factor for boxes and kpts.\n",
    "    res_box_array = np.array([IMG_W , IMG_H,IMG_W,IMG_H])\n",
    "    res_lm_array = np.array([IMG_W, IMG_H])\n",
    "    #NORMALIZE LANDMARKS IN THE RANGE[0,1]\n",
    "    norms_kps_per_img = lm_kpts.copy()\n",
    "    norms_kps_per_img[:,:-1]= norms_kps_per_img[:, :-1] / res_lm_array\n",
    "    norm_bbox_per_img = boxes /res_box_array\n",
    "    \n",
    "    yolo_boxes = norm_bbox_per_img.copy()\n",
    "    yolo_boxes[:2] = norm_bbox_per_img[:2] + norm_bbox_per_img[2:]/2\n",
    "    return yolo_boxes, norm_bbox_per_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
