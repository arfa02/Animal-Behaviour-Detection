{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52795fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from opencv-python) (2.2.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e9d9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "from shutil import copyfile\n",
    "from dataclasses import dataclass\n",
    "import yaml\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8425d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_unzip(url,save_path):\n",
    "    print(\"Downloading and extracting assets...\",end=\"\")\n",
    "    file = requests.get(url)\n",
    "    open(save_path,\"wb\").write(file.content)\n",
    "\n",
    "    try:\n",
    "        #Extract files\n",
    "        if save_path.endswith(\".tar\"):\n",
    "            with tarfile.open(save_path,\"r\") as tar:\n",
    "                tar.extractall(os.path.split(save_path)[0])\n",
    "\n",
    "        print(\"Done\")\n",
    "    except:\n",
    "        print(\"Invalid file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab15890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_URL = r\"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
    "IMAGES_DIR = \"Images\"\n",
    "IMAGES_TAR_PATH = os.path.join(os.getcwd(), f\"{IMAGES_DIR}.tar\")\n",
    "\n",
    "ANNS_METADATA_URL = r\"https://github.com/benjiebob/StanfordExtra/raw/master/keypoint_definitions.csv\"\n",
    "ANNS_METADATA = \"keypoint_definitions.csv\"\n",
    "\n",
    "# Download if dataset does not exists.\n",
    "if not os.path.exists(IMAGES_DIR):\n",
    "    download_unzip(IMAGES_URL, IMAGES_TAR_PATH)\n",
    "    os.remove(IMAGES_TAR_PATH)\n",
    "\n",
    "if not os.path.isfile(ANNS_METADATA):\n",
    "    download_unzip(ANNS_METADATA_URL, ANNS_METADATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e9aba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_PATH = \"StanfordExtra_V12\"\n",
    "JSON_PATH = os.path.join(ANN_PATH, \"StanfordExtra_v12.json\")\n",
    "\n",
    "with open(JSON_PATH) as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4fd2964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 6773\n",
      "Validation Samples: 1703\n"
     ]
    }
   ],
   "source": [
    "train_ids = np.load(os.path.join(ANN_PATH,\n",
    "                                 \"train_stanford_StanfordExtra_v12.npy\"))\n",
    "val_ids = np.load(os.path.join(ANN_PATH,\n",
    "                               \"test_stanford_StanfordExtra_v12.npy\"))\n",
    "\n",
    "print(f\"Train Samples: {len(train_ids)}\")\n",
    "print(f\"Validation Samples: {len(val_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784d521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "389e1b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[ 910  917  920 ... 8977 9745 9742]\n"
     ]
    }
   ],
   "source": [
    "print(type(train_ids))\n",
    "print(train_ids)\n",
    "train_json_data = []\n",
    "for train_id in train_ids:\n",
    "    train_json_data.append(json_data[train_id])\n",
    "\n",
    "val_json_data = []\n",
    "for val_id in val_ids:\n",
    "    val_json_data.append(json_data[val_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bde2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"animal-pose-data\"\n",
    "\n",
    "TRAIN_DIR         = f\"train\"\n",
    "TRAIN_FOLDER_IMG    = f\"images\"\n",
    "TRAIN_FOLDER_LABELS = f\"labels\"\n",
    "\n",
    "TRAIN_IMG_PATH   = os.path.join(DATA_DIR, TRAIN_DIR, TRAIN_FOLDER_IMG)\n",
    "TRAIN_LABEL_PATH = os.path.join(DATA_DIR, TRAIN_DIR, TRAIN_FOLDER_LABELS)\n",
    "\n",
    "VALID_DIR           = f\"valid\"\n",
    "VALID_FOLDER_IMG    = f\"images\"\n",
    "VALID_FOLDER_LABELS = f\"labels\"\n",
    "\n",
    "VALID_IMG_PATH   = os.path.join(DATA_DIR, VALID_DIR, VALID_FOLDER_IMG)\n",
    "VALID_LABEL_PATH = os.path.join(DATA_DIR, VALID_DIR, VALID_FOLDER_LABELS)\n",
    "\n",
    "os.makedirs(TRAIN_IMG_PATH, exist_ok=True)\n",
    "os.makedirs(TRAIN_LABEL_PATH, exist_ok=True)\n",
    "os.makedirs(VALID_IMG_PATH, exist_ok=True)\n",
    "os.makedirs(VALID_LABEL_PATH, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "281b06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_data = []\n",
    "for train_id in train_ids:\n",
    "    train_json_data.append(json_data[train_id])\n",
    "\n",
    "val_json_data = []\n",
    "for val_id in val_ids:\n",
    "    val_json_data.append(json_data[val_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6fadcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_json_data:\n",
    "    img_file = data[\"img_path\"]\n",
    "    filename = img_file.split(\"/\")[-1]\n",
    "    copyfile(os.path.join(IMAGES_DIR, img_file),\n",
    "             os.path.join(TRAIN_IMG_PATH, filename))\n",
    "\n",
    "\n",
    "for data in val_json_data:\n",
    "    img_file = data[\"img_path\"]\n",
    "    filename = img_file.split(\"/\")[-1]\n",
    "    copyfile(os.path.join(IMAGES_DIR, img_file),\n",
    "             os.path.join(VALID_IMG_PATH, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f02355a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91d4f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_boxes_kpts(img_size,boxes,lm_kpts):\n",
    "    IMG_W,IMG_H  = img_size\n",
    "    #modifying the kpts with visibilities as  1s to 2s\n",
    "    vis_ones = np.where(lm_kpts[:, -1] == 1.)\n",
    "    lm_kpts[vis_ones, -1] = 2.\n",
    "    #normalizing factor for boxes and kpts.\n",
    "    res_box_array = np.array([IMG_W , IMG_H,IMG_W,IMG_H])\n",
    "    res_lm_array = np.array([IMG_W, IMG_H])\n",
    "    #NORMALIZE LANDMARKS IN THE RANGE[0,1]\n",
    "    norms_kps_per_img = lm_kpts.copy()\n",
    "    norms_kps_per_img[:,:-1]= norms_kps_per_img[:, :-1] / res_lm_array\n",
    "    norm_bbox_per_img = boxes /res_box_array\n",
    "    \n",
    "    yolo_boxes = norm_bbox_per_img.copy()\n",
    "    yolo_boxes[:2] = norm_bbox_per_img[:2] + norm_bbox_per_img[2:]/2\n",
    "    return yolo_boxes, norm_bbox_per_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c89e32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_txt_files(json_data, LABEL_PATH):\n",
    "    for data in json_data:\n",
    "        IMAGE_ID =data[\"img_path\"].split(\"/\")[-1].split(\".\")[0]\n",
    "        IMG_WIDTH, IMG_HEIGHT = data[\"img_width\"], data[\"img_height\"]\n",
    "        #converting joints into numpy array with float32 for less memory usage\n",
    "        landmarks_kpts = np.nan_to_num(np.array(data[\"joints\"], dtype=np.float32))#nan_to_num is function to convert the nan values to any numeric form.\n",
    "        landmarks_bboxes = np.array(data[\"img_bbox\"],dtype=np.float32)#img_bbox=value representing bounding box coordinates\n",
    "        bboxes_yolo, kpts_yolo = create_yolo_boxes_kpts(\n",
    "            (IMG_WIDTH,IMG_HEIGHT),\n",
    "            landmarks_bboxes,\n",
    "            landmarks_kpts)\n",
    "        TXT_FILE = IMAGE_ID+\".txt\"\n",
    "        with open(os.path.join(LABEL_PATH, TXT_FILE),\"w\") as f:\n",
    "            \"\"\"The bounding box contains four value which is (centre x,centre y,width ,height)\n",
    "            which is normalized to 0 and 1 \n",
    "            .flatten converts the kpt array to 1Darray\"\"\"\n",
    "            x_c_norm, y_c_norm ,box_width_norm, box_height_norm = (round(bboxes_yolo[0],5),\n",
    "                                                                  round(bboxes_yolo[1],5),\n",
    "                                                                  round(bboxes_yolo[2],5),\n",
    "                                                                  round(bboxes_yolo[3],5),)\n",
    "            kps_flattend = [round(ele,5) for ele in kpts_yolo.flatten().tolist()]\n",
    "            line = f\"{CLASS_ID} {x_c_norm} {y_c_norm} {box_width_norm} {box_height_norm}\"\n",
    "            line+= \" \".join(map(str, kps_flattend))#converts kpt to string and join them in one single string\n",
    "            f.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c3acc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yolo_txt_files(train_json_data,TRAIN_LABEL_PATH)\n",
    "create_yolo_txt_files(val_json_data,VALID_LABEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41834f3c",
   "metadata": {},
   "source": [
    "Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89cc2995",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_meta_data = pd.read_csv(\"keypoint_definitions.csv\")\n",
    "COLORS = ann_meta_data[\"Hex colour\"].values.tolist()\n",
    "COLORS_RGB_MAP =[]\n",
    "for color in COLORS:\n",
    "    R, G, B = int(color[:2], 16), int(color[2:4], 16), int(color[4:], 16)#converting hex to decimal\n",
    "    COLORS_RGB_MAP.append({color: (R,G,B)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ae6c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 6773, Validation Images: 1703\n"
     ]
    }
   ],
   "source": [
    "train_images = os.listdir(TRAIN_IMG_PATH)\n",
    "valid_images = os.listdir(VALID_IMG_PATH)\n",
    "\n",
    "print(f\"Training images: {len(train_images)}, Validation Images: {len(valid_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f6c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
